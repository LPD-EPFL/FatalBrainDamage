{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test of regularization with error network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.core import Lambda\n",
    "from keras.initializers import Constant\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.datasets import mnist\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel_reg(layer, errors, is_last, C, p, KLips = 1., lambda_ = 0.1):\n",
    "    \"\"\" Get a DeltaNetwork regularizer for layer\"\"\"\n",
    "\n",
    "    def kernel_reg(w, layer = layer, is_last = is_last, C_layer = C, p_layer = p, KLips = KLips, lambda_ = lambda_):\n",
    "        \"\"\" Regularizer for a layer \"\"\"\n",
    "        # Maximal 1-norm over output neuron\n",
    "        if layer == 0: return 0\n",
    "        W = K.abs(w)\n",
    "\n",
    "        print(\"Error is_last = %d %d = W(pC + K(1-p) DeltaOld) p = %f C = %s K = %f DeltaOld = %s W = %s\" % (is_last, layer, p_layer, str(C_layer), KLips, str(errors[layer - 1]), str(W)))\n",
    "        \n",
    "        # error (induction)\n",
    "        error = K.dot(K.transpose(W), p_layer * C_layer + KLips * (1 - p_layer) * errors[layer - 1])\n",
    "        \n",
    "        # saving the error for the next call\n",
    "        errors[layer] = error\n",
    "\n",
    "        # returning the error scaled\n",
    "        return K.mean(error) * lambda_ if is_last else 0\n",
    "\n",
    "    # returning the function\n",
    "    return kernel_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28 ** 2)\n",
    "x_test = x_test.reshape(-1, 28 ** 2)\n",
    "digits = {x: [1 if y == x else 0 for y in range(10)] for x in range(10)}\n",
    "y_train = np.array([digits[y] for y in y_train])\n",
    "y_test = np.array([digits[y] for y in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max per layer variable\n",
    "C1 = K.variable(value = np.zeros((11, 1)))\n",
    "C2 = K.variable(value = np.zeros((12, 1)))\n",
    "C3 = K.variable(value = np.zeros((13, 1)))\n",
    "C = [C1, C2, C3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first layer of error network\n",
    "errors = {0: K.variable(value = np.zeros((11, 1)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error is_last = 0 1 = W(pC + K(1-p) DeltaOld) p = 0.100000 C = <tf.Variable 'Variable:0' shape=(11, 1) dtype=float32_ref> K = 2.000000 DeltaOld = <tf.Variable 'Variable_4:0' shape=(11, 1) dtype=float32_ref> W = Tensor(\"dense_6/weight_regularizer/Abs:0\", shape=(11, 12), dtype=float32)\n",
      "Error is_last = 0 2 = W(pC + K(1-p) DeltaOld) p = 0.100000 C = <tf.Variable 'Variable_1:0' shape=(12, 1) dtype=float32_ref> K = 2.000000 DeltaOld = Tensor(\"dense_6/weight_regularizer/MatMul:0\", shape=(12, 1), dtype=float32) W = Tensor(\"dense_7/weight_regularizer/Abs:0\", shape=(12, 13), dtype=float32)\n",
      "Error is_last = 1 3 = W(pC + K(1-p) DeltaOld) p = 0.100000 C = <tf.Variable 'Variable_2:0' shape=(13, 1) dtype=float32_ref> K = 2.000000 DeltaOld = Tensor(\"dense_7/weight_regularizer/MatMul:0\", shape=(13, 1), dtype=float32) W = Tensor(\"dense_8/weight_regularizer/Abs:0\", shape=(13, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# defining the network\n",
    "model = Sequential()\n",
    "model.add(Dense(11, kernel_initializer = 'random_normal', activation = 'relu', input_shape = (784,)))\n",
    "model.add(Dense(12, kernel_initializer = 'random_normal', activation = 'relu', kernel_regularizer = get_kernel_reg(1, errors, False, C1, 0.1, 2., 0)))\n",
    "model.add(Dense(13, kernel_initializer = 'random_normal', activation = 'relu', kernel_regularizer = get_kernel_reg(2, errors, False, C2, 0.1, 2., 0)))\n",
    "model.add(Dense(10, kernel_initializer = 'random_normal', activation = 'linear', kernel_regularizer = get_kernel_reg(3, errors, True, C3, 0.1, 2., 0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating mean per neuron bound\n",
    "inp = model.input\n",
    "outputs = [K.mean(K.abs(layer.output), axis = 0) for layer in model.layers]\n",
    "mean_per_neuron = lambda x : (K.function([inp, K.learning_phase()], outputs))([x, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating delta network output\n",
    "delta_network = lambda x : (K.function([inp, K.learning_phase()], [K.mean(errors[3])]))([x, 1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(loss=keras.losses.mean_squared_error,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy', 'mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.1340 - acc: 0.0911 - mean_squared_error: 0.1084 - val_loss: 0.1230 - val_acc: 0.1047 - val_mean_squared_error: 0.1002\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.1113 - acc: 0.1053 - mean_squared_error: 0.0994 - val_loss: 0.1086 - val_acc: 0.1054 - val_mean_squared_error: 0.0975\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.1081 - acc: 0.1075 - mean_squared_error: 0.0970 - val_loss: 0.1060 - val_acc: 0.1108 - val_mean_squared_error: 0.0956\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.1058 - acc: 0.1148 - mean_squared_error: 0.0951 - val_loss: 0.1037 - val_acc: 0.1264 - val_mean_squared_error: 0.0937\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.1036 - acc: 0.1323 - mean_squared_error: 0.0932 - val_loss: 0.1012 - val_acc: 0.1399 - val_mean_squared_error: 0.0915\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.1012 - acc: 0.1415 - mean_squared_error: 0.0909 - val_loss: 0.0991 - val_acc: 0.1446 - val_mean_squared_error: 0.0895\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0992 - acc: 0.1562 - mean_squared_error: 0.0892 - val_loss: 0.0977 - val_acc: 0.1709 - val_mean_squared_error: 0.0883\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0977 - acc: 0.1909 - mean_squared_error: 0.0880 - val_loss: 0.0964 - val_acc: 0.2150 - val_mean_squared_error: 0.0873\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0964 - acc: 0.2299 - mean_squared_error: 0.0870 - val_loss: 0.0951 - val_acc: 0.2618 - val_mean_squared_error: 0.0863\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0951 - acc: 0.2903 - mean_squared_error: 0.0860 - val_loss: 0.0940 - val_acc: 0.3291 - val_mean_squared_error: 0.0853\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0940 - acc: 0.3463 - mean_squared_error: 0.0851 - val_loss: 0.0928 - val_acc: 0.3614 - val_mean_squared_error: 0.0843\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0928 - acc: 0.3683 - mean_squared_error: 0.0841 - val_loss: 0.0916 - val_acc: 0.3905 - val_mean_squared_error: 0.0833\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0916 - acc: 0.3857 - mean_squared_error: 0.0831 - val_loss: 0.0904 - val_acc: 0.4128 - val_mean_squared_error: 0.0821\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0905 - acc: 0.3944 - mean_squared_error: 0.0821 - val_loss: 0.0910 - val_acc: 0.3736 - val_mean_squared_error: 0.0829\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0911 - acc: 0.3644 - mean_squared_error: 0.0828 - val_loss: 0.0898 - val_acc: 0.3986 - val_mean_squared_error: 0.0819\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0889 - acc: 0.4018 - mean_squared_error: 0.0811 - val_loss: 0.0872 - val_acc: 0.4228 - val_mean_squared_error: 0.0796\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0870 - acc: 0.4339 - mean_squared_error: 0.0793 - val_loss: 0.0859 - val_acc: 0.4345 - val_mean_squared_error: 0.0784\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0858 - acc: 0.4428 - mean_squared_error: 0.0782 - val_loss: 0.0852 - val_acc: 0.4231 - val_mean_squared_error: 0.0777\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0857 - acc: 0.4324 - mean_squared_error: 0.0780 - val_loss: 0.0850 - val_acc: 0.4219 - val_mean_squared_error: 0.0775\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0846 - acc: 0.4398 - mean_squared_error: 0.0772 - val_loss: 0.0832 - val_acc: 0.4283 - val_mean_squared_error: 0.0759\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0829 - acc: 0.4408 - mean_squared_error: 0.0755 - val_loss: 0.0821 - val_acc: 0.4313 - val_mean_squared_error: 0.0749\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0818 - acc: 0.4414 - mean_squared_error: 0.0744 - val_loss: 0.0816 - val_acc: 0.4244 - val_mean_squared_error: 0.0744\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0809 - acc: 0.4399 - mean_squared_error: 0.0736 - val_loss: 0.0801 - val_acc: 0.4352 - val_mean_squared_error: 0.0729\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0795 - acc: 0.4441 - mean_squared_error: 0.0723 - val_loss: 0.0789 - val_acc: 0.4442 - val_mean_squared_error: 0.0717\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0784 - acc: 0.4495 - mean_squared_error: 0.0712 - val_loss: 0.0779 - val_acc: 0.4468 - val_mean_squared_error: 0.0708\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0778 - acc: 0.4571 - mean_squared_error: 0.0707 - val_loss: 0.0781 - val_acc: 0.4454 - val_mean_squared_error: 0.0710\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0771 - acc: 0.4603 - mean_squared_error: 0.0702 - val_loss: 0.0746 - val_acc: 0.4591 - val_mean_squared_error: 0.0678\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0748 - acc: 0.4670 - mean_squared_error: 0.0679 - val_loss: 0.0758 - val_acc: 0.4347 - val_mean_squared_error: 0.0689\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0761 - acc: 0.4571 - mean_squared_error: 0.0692 - val_loss: 0.0751 - val_acc: 0.4409 - val_mean_squared_error: 0.0682\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0743 - acc: 0.4602 - mean_squared_error: 0.0676 - val_loss: 0.0722 - val_acc: 0.4672 - val_mean_squared_error: 0.0656\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0722 - acc: 0.4742 - mean_squared_error: 0.0655 - val_loss: 0.0718 - val_acc: 0.4676 - val_mean_squared_error: 0.0652\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0720 - acc: 0.4837 - mean_squared_error: 0.0653 - val_loss: 0.0718 - val_acc: 0.4652 - val_mean_squared_error: 0.0652\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0719 - acc: 0.4726 - mean_squared_error: 0.0652 - val_loss: 0.0715 - val_acc: 0.4702 - val_mean_squared_error: 0.0649\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0713 - acc: 0.4794 - mean_squared_error: 0.0648 - val_loss: 0.0705 - val_acc: 0.4788 - val_mean_squared_error: 0.0641\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0704 - acc: 0.4951 - mean_squared_error: 0.0639 - val_loss: 0.0695 - val_acc: 0.4829 - val_mean_squared_error: 0.0631\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0696 - acc: 0.4924 - mean_squared_error: 0.0631 - val_loss: 0.0696 - val_acc: 0.4773 - val_mean_squared_error: 0.0631\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0696 - acc: 0.4936 - mean_squared_error: 0.0632 - val_loss: 0.0698 - val_acc: 0.4776 - val_mean_squared_error: 0.0634\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0697 - acc: 0.4993 - mean_squared_error: 0.0633 - val_loss: 0.0688 - val_acc: 0.5200 - val_mean_squared_error: 0.0623\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0685 - acc: 0.5222 - mean_squared_error: 0.0622 - val_loss: 0.0675 - val_acc: 0.5143 - val_mean_squared_error: 0.0613\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0675 - acc: 0.5112 - mean_squared_error: 0.0614 - val_loss: 0.0671 - val_acc: 0.5192 - val_mean_squared_error: 0.0610\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0674 - acc: 0.5169 - mean_squared_error: 0.0613 - val_loss: 0.0678 - val_acc: 0.5126 - val_mean_squared_error: 0.0616\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0681 - acc: 0.5145 - mean_squared_error: 0.0620 - val_loss: 0.0671 - val_acc: 0.5297 - val_mean_squared_error: 0.0609\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0668 - acc: 0.5306 - mean_squared_error: 0.0608 - val_loss: 0.0657 - val_acc: 0.5602 - val_mean_squared_error: 0.0597\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0658 - acc: 0.5449 - mean_squared_error: 0.0598 - val_loss: 0.0658 - val_acc: 0.5390 - val_mean_squared_error: 0.0598\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0663 - acc: 0.5326 - mean_squared_error: 0.0602 - val_loss: 0.0658 - val_acc: 0.5332 - val_mean_squared_error: 0.0597\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0657 - acc: 0.5369 - mean_squared_error: 0.0598 - val_loss: 0.0649 - val_acc: 0.5622 - val_mean_squared_error: 0.0590\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0652 - acc: 0.5515 - mean_squared_error: 0.0593 - val_loss: 0.0653 - val_acc: 0.5449 - val_mean_squared_error: 0.0594\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0656 - acc: 0.5376 - mean_squared_error: 0.0598 - val_loss: 0.0648 - val_acc: 0.5476 - val_mean_squared_error: 0.0589\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0647 - acc: 0.5500 - mean_squared_error: 0.0589 - val_loss: 0.0638 - val_acc: 0.5620 - val_mean_squared_error: 0.0581\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0642 - acc: 0.5569 - mean_squared_error: 0.0585 - val_loss: 0.0643 - val_acc: 0.5608 - val_mean_squared_error: 0.0585\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0647 - acc: 0.5450 - mean_squared_error: 0.0589 - val_loss: 0.0639 - val_acc: 0.5645 - val_mean_squared_error: 0.0581\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0639 - acc: 0.5565 - mean_squared_error: 0.0582 - val_loss: 0.0631 - val_acc: 0.5774 - val_mean_squared_error: 0.0574\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0633 - acc: 0.5707 - mean_squared_error: 0.0577 - val_loss: 0.0630 - val_acc: 0.5781 - val_mean_squared_error: 0.0574\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0634 - acc: 0.5674 - mean_squared_error: 0.0577 - val_loss: 0.0630 - val_acc: 0.5833 - val_mean_squared_error: 0.0573\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0633 - acc: 0.5709 - mean_squared_error: 0.0577 - val_loss: 0.0629 - val_acc: 0.5815 - val_mean_squared_error: 0.0572\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0630 - acc: 0.5735 - mean_squared_error: 0.0574 - val_loss: 0.0620 - val_acc: 0.5733 - val_mean_squared_error: 0.0564\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0623 - acc: 0.5766 - mean_squared_error: 0.0567 - val_loss: 0.0619 - val_acc: 0.5633 - val_mean_squared_error: 0.0563\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0623 - acc: 0.5646 - mean_squared_error: 0.0567 - val_loss: 0.0622 - val_acc: 0.5574 - val_mean_squared_error: 0.0566\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0620 - acc: 0.5684 - mean_squared_error: 0.0565 - val_loss: 0.0612 - val_acc: 0.5665 - val_mean_squared_error: 0.0556\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0616 - acc: 0.5790 - mean_squared_error: 0.0560 - val_loss: 0.0614 - val_acc: 0.5650 - val_mean_squared_error: 0.0558\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0613 - acc: 0.5725 - mean_squared_error: 0.0557 - val_loss: 0.0603 - val_acc: 0.5730 - val_mean_squared_error: 0.0548\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0608 - acc: 0.5856 - mean_squared_error: 0.0552 - val_loss: 0.0606 - val_acc: 0.5640 - val_mean_squared_error: 0.0550\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0605 - acc: 0.5767 - mean_squared_error: 0.0550 - val_loss: 0.0599 - val_acc: 0.5727 - val_mean_squared_error: 0.0543\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0604 - acc: 0.5927 - mean_squared_error: 0.0548 - val_loss: 0.0608 - val_acc: 0.5596 - val_mean_squared_error: 0.0552\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0608 - acc: 0.5645 - mean_squared_error: 0.0551 - val_loss: 0.0601 - val_acc: 0.5723 - val_mean_squared_error: 0.0546\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0615 - acc: 0.5876 - mean_squared_error: 0.0558 - val_loss: 0.0621 - val_acc: 0.5460 - val_mean_squared_error: 0.0565\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0619 - acc: 0.5468 - mean_squared_error: 0.0564 - val_loss: 0.0588 - val_acc: 0.5877 - val_mean_squared_error: 0.0534\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0592 - acc: 0.5889 - mean_squared_error: 0.0537 - val_loss: 0.0583 - val_acc: 0.5832 - val_mean_squared_error: 0.0529\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0591 - acc: 0.5934 - mean_squared_error: 0.0536 - val_loss: 0.0594 - val_acc: 0.5635 - val_mean_squared_error: 0.0540\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0599 - acc: 0.5880 - mean_squared_error: 0.0544 - val_loss: 0.0591 - val_acc: 0.5637 - val_mean_squared_error: 0.0537\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0592 - acc: 0.5879 - mean_squared_error: 0.0538 - val_loss: 0.0580 - val_acc: 0.5804 - val_mean_squared_error: 0.0526\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0585 - acc: 0.6012 - mean_squared_error: 0.0530 - val_loss: 0.0577 - val_acc: 0.5802 - val_mean_squared_error: 0.0523\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0583 - acc: 0.6067 - mean_squared_error: 0.0528 - val_loss: 0.0578 - val_acc: 0.5741 - val_mean_squared_error: 0.0524\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0582 - acc: 0.6057 - mean_squared_error: 0.0527 - val_loss: 0.0572 - val_acc: 0.5834 - val_mean_squared_error: 0.0517\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0577 - acc: 0.6149 - mean_squared_error: 0.0522 - val_loss: 0.0569 - val_acc: 0.5817 - val_mean_squared_error: 0.0515\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0575 - acc: 0.6165 - mean_squared_error: 0.0519 - val_loss: 0.0568 - val_acc: 0.5772 - val_mean_squared_error: 0.0513\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0572 - acc: 0.6172 - mean_squared_error: 0.0517 - val_loss: 0.0566 - val_acc: 0.5757 - val_mean_squared_error: 0.0511\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0569 - acc: 0.6178 - mean_squared_error: 0.0514 - val_loss: 0.0571 - val_acc: 0.5722 - val_mean_squared_error: 0.0515\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0574 - acc: 0.6155 - mean_squared_error: 0.0519 - val_loss: 0.0598 - val_acc: 0.5646 - val_mean_squared_error: 0.0540\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0593 - acc: 0.5978 - mean_squared_error: 0.0537 - val_loss: 0.0582 - val_acc: 0.5758 - val_mean_squared_error: 0.0525\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0574 - acc: 0.6144 - mean_squared_error: 0.0519 - val_loss: 0.0556 - val_acc: 0.5960 - val_mean_squared_error: 0.0501\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0558 - acc: 0.6285 - mean_squared_error: 0.0503 - val_loss: 0.0556 - val_acc: 0.5931 - val_mean_squared_error: 0.0501\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0559 - acc: 0.6271 - mean_squared_error: 0.0503 - val_loss: 0.0562 - val_acc: 0.5881 - val_mean_squared_error: 0.0505\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0561 - acc: 0.6245 - mean_squared_error: 0.0504 - val_loss: 0.0558 - val_acc: 0.5925 - val_mean_squared_error: 0.0501\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0557 - acc: 0.6244 - mean_squared_error: 0.0500 - val_loss: 0.0553 - val_acc: 0.6006 - val_mean_squared_error: 0.0496\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0552 - acc: 0.6280 - mean_squared_error: 0.0496 - val_loss: 0.0551 - val_acc: 0.6059 - val_mean_squared_error: 0.0493\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0552 - acc: 0.6292 - mean_squared_error: 0.0495 - val_loss: 0.0555 - val_acc: 0.5961 - val_mean_squared_error: 0.0497\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0552 - acc: 0.6230 - mean_squared_error: 0.0495 - val_loss: 0.0544 - val_acc: 0.6139 - val_mean_squared_error: 0.0486\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0545 - acc: 0.6337 - mean_squared_error: 0.0488 - val_loss: 0.0547 - val_acc: 0.6080 - val_mean_squared_error: 0.0489\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0545 - acc: 0.6322 - mean_squared_error: 0.0487 - val_loss: 0.0541 - val_acc: 0.6153 - val_mean_squared_error: 0.0483\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0540 - acc: 0.6363 - mean_squared_error: 0.0483 - val_loss: 0.0537 - val_acc: 0.6244 - val_mean_squared_error: 0.0479\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0540 - acc: 0.6435 - mean_squared_error: 0.0482 - val_loss: 0.0546 - val_acc: 0.6125 - val_mean_squared_error: 0.0487\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0543 - acc: 0.6376 - mean_squared_error: 0.0485 - val_loss: 0.0535 - val_acc: 0.6235 - val_mean_squared_error: 0.0477\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0537 - acc: 0.6447 - mean_squared_error: 0.0479 - val_loss: 0.0539 - val_acc: 0.6250 - val_mean_squared_error: 0.0480\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0540 - acc: 0.6471 - mean_squared_error: 0.0482 - val_loss: 0.0538 - val_acc: 0.6259 - val_mean_squared_error: 0.0479\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0536 - acc: 0.6476 - mean_squared_error: 0.0478 - val_loss: 0.0528 - val_acc: 0.6452 - val_mean_squared_error: 0.0469\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0529 - acc: 0.6601 - mean_squared_error: 0.0470 - val_loss: 0.0526 - val_acc: 0.6468 - val_mean_squared_error: 0.0467\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0530 - acc: 0.6599 - mean_squared_error: 0.0471 - val_loss: 0.0536 - val_acc: 0.6298 - val_mean_squared_error: 0.0476\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0532 - acc: 0.6558 - mean_squared_error: 0.0473 - val_loss: 0.0524 - val_acc: 0.6482 - val_mean_squared_error: 0.0464\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/60000 [==============>...............] - ETA: 0s - loss: 0.0530 - acc: 0.6462 - mean_squared_error: 0.0470\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0526 - acc: 0.6620 - mean_squared_error: 0.0467 - val_loss: 0.0526 - val_acc: 0.6433 - val_mean_squared_error: 0.0466\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "history = []\n",
    "deltas = []\n",
    "for i in range(100):\n",
    "    history += [model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = 1, batch_size = 30000)]\n",
    "    for C_, v in zip(C, mean_per_neuron(x_train)):\n",
    "        K.set_value(C_, v.reshape(-1, 1))\n",
    "    deltas += [delta_network(x_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining accuracy\n",
    "acc = [x for h in history for x in h.history['acc']]\n",
    "val_acc = [x for h in history for x in h.history['val_acc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the training data\n",
    "plt.figure()\n",
    "plt.title('Accuracy while training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy/Error')\n",
    "plt.plot(acc, label = 'Accuracy')\n",
    "plt.plot(val_acc, label = 'Validation accuracy')\n",
    "plt.plot(deltas, label = 'Error Network Output')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
