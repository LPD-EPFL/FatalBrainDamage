{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from experiment_mnist import *\n",
    "from tfshow import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['l1', 'l2', 'delta', 'dropout', 'none']\n",
    "activations = ['sigmoid', 'relu']\n",
    "layers = [1,2,3,4,5,6]\n",
    "reg_coeff = np.logspace(-3,3,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 7,960\n",
      "Trainable params: 7,960\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.1060 - acc: 0.1013 - mean_squared_error: 0.1060 - val_loss: 0.0973 - val_acc: 0.1055 - val_mean_squared_error: 0.0973\n",
      "Epoch 2/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0939 - acc: 0.1273 - mean_squared_error: 0.0939 - val_loss: 0.0900 - val_acc: 0.1523 - val_mean_squared_error: 0.0900\n",
      "Epoch 3/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0887 - acc: 0.1874 - mean_squared_error: 0.0887 - val_loss: 0.0870 - val_acc: 0.2363 - val_mean_squared_error: 0.0870\n",
      "Epoch 4/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0863 - acc: 0.2478 - mean_squared_error: 0.0863 - val_loss: 0.0849 - val_acc: 0.3007 - val_mean_squared_error: 0.0849\n",
      "Epoch 5/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0841 - acc: 0.3247 - mean_squared_error: 0.0841 - val_loss: 0.0826 - val_acc: 0.3694 - val_mean_squared_error: 0.0826\n",
      "Epoch 6/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0820 - acc: 0.3729 - mean_squared_error: 0.0820 - val_loss: 0.0808 - val_acc: 0.4026 - val_mean_squared_error: 0.0808\n",
      "Epoch 7/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0801 - acc: 0.4055 - mean_squared_error: 0.0801 - val_loss: 0.0790 - val_acc: 0.4222 - val_mean_squared_error: 0.0790\n",
      "Epoch 8/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0784 - acc: 0.4355 - mean_squared_error: 0.0784 - val_loss: 0.0774 - val_acc: 0.4491 - val_mean_squared_error: 0.0774\n",
      "Epoch 9/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0768 - acc: 0.4646 - mean_squared_error: 0.0768 - val_loss: 0.0758 - val_acc: 0.4889 - val_mean_squared_error: 0.0758\n",
      "Epoch 10/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0751 - acc: 0.4992 - mean_squared_error: 0.0751 - val_loss: 0.0741 - val_acc: 0.5195 - val_mean_squared_error: 0.0741\n",
      "Epoch 11/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0735 - acc: 0.5250 - mean_squared_error: 0.0735 - val_loss: 0.0725 - val_acc: 0.5420 - val_mean_squared_error: 0.0725\n",
      "Epoch 12/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0720 - acc: 0.5466 - mean_squared_error: 0.0720 - val_loss: 0.0711 - val_acc: 0.5601 - val_mean_squared_error: 0.0711\n",
      "Epoch 13/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0706 - acc: 0.5628 - mean_squared_error: 0.0706 - val_loss: 0.0697 - val_acc: 0.5709 - val_mean_squared_error: 0.0697\n",
      "Epoch 14/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0692 - acc: 0.5733 - mean_squared_error: 0.0692 - val_loss: 0.0685 - val_acc: 0.5780 - val_mean_squared_error: 0.0685\n",
      "Epoch 15/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0679 - acc: 0.5841 - mean_squared_error: 0.0679 - val_loss: 0.0672 - val_acc: 0.5877 - val_mean_squared_error: 0.0672\n",
      "Epoch 16/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0667 - acc: 0.5906 - mean_squared_error: 0.0667 - val_loss: 0.0660 - val_acc: 0.5993 - val_mean_squared_error: 0.0660\n",
      "Epoch 17/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0656 - acc: 0.6017 - mean_squared_error: 0.0656 - val_loss: 0.0649 - val_acc: 0.6065 - val_mean_squared_error: 0.0649\n",
      "Epoch 18/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0644 - acc: 0.6083 - mean_squared_error: 0.0644 - val_loss: 0.0637 - val_acc: 0.6150 - val_mean_squared_error: 0.0637\n",
      "Epoch 19/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0633 - acc: 0.6158 - mean_squared_error: 0.0633 - val_loss: 0.0627 - val_acc: 0.6179 - val_mean_squared_error: 0.0627\n",
      "Epoch 20/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0623 - acc: 0.6252 - mean_squared_error: 0.0623 - val_loss: 0.0615 - val_acc: 0.6365 - val_mean_squared_error: 0.0615\n",
      "Epoch 21/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0612 - acc: 0.6420 - mean_squared_error: 0.0612 - val_loss: 0.0604 - val_acc: 0.6478 - val_mean_squared_error: 0.0604\n",
      "Epoch 22/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0603 - acc: 0.6488 - mean_squared_error: 0.0603 - val_loss: 0.0594 - val_acc: 0.6590 - val_mean_squared_error: 0.0594\n",
      "Epoch 23/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0592 - acc: 0.6565 - mean_squared_error: 0.0592 - val_loss: 0.0584 - val_acc: 0.6564 - val_mean_squared_error: 0.0584\n",
      "Epoch 24/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0584 - acc: 0.6594 - mean_squared_error: 0.0584 - val_loss: 0.0575 - val_acc: 0.6730 - val_mean_squared_error: 0.0575\n",
      "Epoch 25/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0575 - acc: 0.6696 - mean_squared_error: 0.0575 - val_loss: 0.0567 - val_acc: 0.6796 - val_mean_squared_error: 0.0567\n",
      "Epoch 26/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0567 - acc: 0.6737 - mean_squared_error: 0.0567 - val_loss: 0.0558 - val_acc: 0.6791 - val_mean_squared_error: 0.0558\n",
      "Epoch 27/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0558 - acc: 0.6808 - mean_squared_error: 0.0558 - val_loss: 0.0550 - val_acc: 0.6839 - val_mean_squared_error: 0.0550\n",
      "Epoch 28/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0549 - acc: 0.6865 - mean_squared_error: 0.0549 - val_loss: 0.0542 - val_acc: 0.6972 - val_mean_squared_error: 0.0542\n",
      "Epoch 29/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0542 - acc: 0.6924 - mean_squared_error: 0.0542 - val_loss: 0.0535 - val_acc: 0.6998 - val_mean_squared_error: 0.0535\n",
      "Epoch 30/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0535 - acc: 0.6976 - mean_squared_error: 0.0535 - val_loss: 0.0529 - val_acc: 0.7103 - val_mean_squared_error: 0.0529\n",
      "Epoch 31/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0527 - acc: 0.7031 - mean_squared_error: 0.0527 - val_loss: 0.0521 - val_acc: 0.7056 - val_mean_squared_error: 0.0521\n",
      "Epoch 32/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0520 - acc: 0.7105 - mean_squared_error: 0.0520 - val_loss: 0.0514 - val_acc: 0.7257 - val_mean_squared_error: 0.0514\n",
      "Epoch 33/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0514 - acc: 0.7172 - mean_squared_error: 0.0514 - val_loss: 0.0507 - val_acc: 0.7258 - val_mean_squared_error: 0.0507\n",
      "Epoch 34/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0509 - acc: 0.7228 - mean_squared_error: 0.0509 - val_loss: 0.0502 - val_acc: 0.7265 - val_mean_squared_error: 0.0502\n",
      "Epoch 35/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0504 - acc: 0.7238 - mean_squared_error: 0.0504 - val_loss: 0.0496 - val_acc: 0.7383 - val_mean_squared_error: 0.0496\n",
      "Epoch 36/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0499 - acc: 0.7296 - mean_squared_error: 0.0499 - val_loss: 0.0492 - val_acc: 0.7371 - val_mean_squared_error: 0.0492\n",
      "Epoch 37/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0494 - acc: 0.7381 - mean_squared_error: 0.0494 - val_loss: 0.0491 - val_acc: 0.7484 - val_mean_squared_error: 0.0491\n",
      "Epoch 38/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0490 - acc: 0.7414 - mean_squared_error: 0.0490 - val_loss: 0.0483 - val_acc: 0.7441 - val_mean_squared_error: 0.0483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0486 - acc: 0.7450 - mean_squared_error: 0.0486 - val_loss: 0.0479 - val_acc: 0.7557 - val_mean_squared_error: 0.0479\n",
      "Epoch 40/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0481 - acc: 0.7520 - mean_squared_error: 0.0481 - val_loss: 0.0473 - val_acc: 0.7620 - val_mean_squared_error: 0.0473\n",
      "Epoch 41/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0476 - acc: 0.7529 - mean_squared_error: 0.0476 - val_loss: 0.0472 - val_acc: 0.7611 - val_mean_squared_error: 0.0472\n",
      "Epoch 42/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0473 - acc: 0.7576 - mean_squared_error: 0.0473 - val_loss: 0.0469 - val_acc: 0.7533 - val_mean_squared_error: 0.0469\n",
      "Epoch 43/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0468 - acc: 0.7578 - mean_squared_error: 0.0468 - val_loss: 0.0463 - val_acc: 0.7681 - val_mean_squared_error: 0.0463\n",
      "Epoch 44/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0465 - acc: 0.7591 - mean_squared_error: 0.0465 - val_loss: 0.0459 - val_acc: 0.7629 - val_mean_squared_error: 0.0459\n",
      "Epoch 45/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0461 - acc: 0.7602 - mean_squared_error: 0.0461 - val_loss: 0.0457 - val_acc: 0.7634 - val_mean_squared_error: 0.0457\n",
      "Epoch 46/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0459 - acc: 0.7635 - mean_squared_error: 0.0459 - val_loss: 0.0455 - val_acc: 0.7634 - val_mean_squared_error: 0.0455\n",
      "Epoch 47/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0454 - acc: 0.7636 - mean_squared_error: 0.0454 - val_loss: 0.0450 - val_acc: 0.7658 - val_mean_squared_error: 0.0450\n",
      "Epoch 48/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0451 - acc: 0.7655 - mean_squared_error: 0.0451 - val_loss: 0.0449 - val_acc: 0.7618 - val_mean_squared_error: 0.0449\n",
      "Epoch 49/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0450 - acc: 0.7649 - mean_squared_error: 0.0450 - val_loss: 0.0444 - val_acc: 0.7702 - val_mean_squared_error: 0.0444\n",
      "Epoch 50/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0446 - acc: 0.7693 - mean_squared_error: 0.0446 - val_loss: 0.0444 - val_acc: 0.7702 - val_mean_squared_error: 0.0444\n",
      "Epoch 51/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0444 - acc: 0.7690 - mean_squared_error: 0.0444 - val_loss: 0.0440 - val_acc: 0.7673 - val_mean_squared_error: 0.0440\n",
      "Epoch 52/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0442 - acc: 0.7709 - mean_squared_error: 0.0442 - val_loss: 0.0439 - val_acc: 0.7693 - val_mean_squared_error: 0.0439\n",
      "Epoch 53/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0438 - acc: 0.7717 - mean_squared_error: 0.0438 - val_loss: 0.0437 - val_acc: 0.7713 - val_mean_squared_error: 0.0437\n",
      "Epoch 54/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0436 - acc: 0.7723 - mean_squared_error: 0.0436 - val_loss: 0.0431 - val_acc: 0.7742 - val_mean_squared_error: 0.0431\n",
      "Epoch 55/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0432 - acc: 0.7745 - mean_squared_error: 0.0432 - val_loss: 0.0429 - val_acc: 0.7743 - val_mean_squared_error: 0.0429\n",
      "Epoch 56/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0431 - acc: 0.7739 - mean_squared_error: 0.0431 - val_loss: 0.0426 - val_acc: 0.7760 - val_mean_squared_error: 0.0426\n",
      "Epoch 57/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0428 - acc: 0.7742 - mean_squared_error: 0.0428 - val_loss: 0.0424 - val_acc: 0.7754 - val_mean_squared_error: 0.0424\n",
      "Epoch 58/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0425 - acc: 0.7752 - mean_squared_error: 0.0425 - val_loss: 0.0422 - val_acc: 0.7723 - val_mean_squared_error: 0.0422\n",
      "Epoch 59/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0424 - acc: 0.7758 - mean_squared_error: 0.0424 - val_loss: 0.0419 - val_acc: 0.7782 - val_mean_squared_error: 0.0419\n",
      "Epoch 60/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0420 - acc: 0.7764 - mean_squared_error: 0.0420 - val_loss: 0.0419 - val_acc: 0.7778 - val_mean_squared_error: 0.0419\n",
      "Epoch 61/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0418 - acc: 0.7760 - mean_squared_error: 0.0418 - val_loss: 0.0412 - val_acc: 0.7785 - val_mean_squared_error: 0.0412\n",
      "Epoch 62/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0414 - acc: 0.7772 - mean_squared_error: 0.0414 - val_loss: 0.0410 - val_acc: 0.7802 - val_mean_squared_error: 0.0410\n",
      "Epoch 63/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0411 - acc: 0.7781 - mean_squared_error: 0.0411 - val_loss: 0.0407 - val_acc: 0.7788 - val_mean_squared_error: 0.0407\n",
      "Epoch 64/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0409 - acc: 0.7767 - mean_squared_error: 0.0409 - val_loss: 0.0404 - val_acc: 0.7783 - val_mean_squared_error: 0.0404\n",
      "Epoch 65/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0405 - acc: 0.7776 - mean_squared_error: 0.0405 - val_loss: 0.0402 - val_acc: 0.7777 - val_mean_squared_error: 0.0402\n",
      "Epoch 66/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0403 - acc: 0.7783 - mean_squared_error: 0.0403 - val_loss: 0.0402 - val_acc: 0.7798 - val_mean_squared_error: 0.0402\n",
      "Epoch 67/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0401 - acc: 0.7786 - mean_squared_error: 0.0401 - val_loss: 0.0399 - val_acc: 0.7798 - val_mean_squared_error: 0.0399\n",
      "Epoch 68/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0400 - acc: 0.7768 - mean_squared_error: 0.0400 - val_loss: 0.0397 - val_acc: 0.7779 - val_mean_squared_error: 0.0397\n",
      "Epoch 69/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0397 - acc: 0.7782 - mean_squared_error: 0.0397 - val_loss: 0.0396 - val_acc: 0.7759 - val_mean_squared_error: 0.0396\n",
      "Epoch 70/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0396 - acc: 0.7786 - mean_squared_error: 0.0396 - val_loss: 0.0395 - val_acc: 0.7783 - val_mean_squared_error: 0.0395\n",
      "Epoch 71/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0395 - acc: 0.7795 - mean_squared_error: 0.0395 - val_loss: 0.0392 - val_acc: 0.7819 - val_mean_squared_error: 0.0392\n",
      "Epoch 72/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0393 - acc: 0.7791 - mean_squared_error: 0.0393 - val_loss: 0.0390 - val_acc: 0.7804 - val_mean_squared_error: 0.0390\n",
      "Epoch 73/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0391 - acc: 0.7805 - mean_squared_error: 0.0391 - val_loss: 0.0389 - val_acc: 0.7800 - val_mean_squared_error: 0.0389\n",
      "Epoch 74/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0391 - acc: 0.7803 - mean_squared_error: 0.0391 - val_loss: 0.0390 - val_acc: 0.7814 - val_mean_squared_error: 0.0390\n",
      "Epoch 75/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0389 - acc: 0.7819 - mean_squared_error: 0.0389 - val_loss: 0.0388 - val_acc: 0.7808 - val_mean_squared_error: 0.0388\n",
      "Epoch 76/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0387 - acc: 0.7813 - mean_squared_error: 0.0387 - val_loss: 0.0387 - val_acc: 0.7858 - val_mean_squared_error: 0.0387\n",
      "Epoch 77/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0386 - acc: 0.7819 - mean_squared_error: 0.0386 - val_loss: 0.0384 - val_acc: 0.7823 - val_mean_squared_error: 0.0384\n",
      "Epoch 78/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0384 - acc: 0.7817 - mean_squared_error: 0.0384 - val_loss: 0.0383 - val_acc: 0.7817 - val_mean_squared_error: 0.0383\n",
      "Epoch 79/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0384 - acc: 0.7808 - mean_squared_error: 0.0384 - val_loss: 0.0383 - val_acc: 0.7818 - val_mean_squared_error: 0.0383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0383 - acc: 0.7832 - mean_squared_error: 0.0383 - val_loss: 0.0380 - val_acc: 0.7841 - val_mean_squared_error: 0.0380\n",
      "Epoch 81/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0381 - acc: 0.7827 - mean_squared_error: 0.0381 - val_loss: 0.0379 - val_acc: 0.7840 - val_mean_squared_error: 0.0379\n",
      "Epoch 82/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0379 - acc: 0.7850 - mean_squared_error: 0.0379 - val_loss: 0.0380 - val_acc: 0.7824 - val_mean_squared_error: 0.0380\n",
      "Epoch 83/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0380 - acc: 0.7833 - mean_squared_error: 0.0380 - val_loss: 0.0380 - val_acc: 0.7829 - val_mean_squared_error: 0.0380\n",
      "Epoch 84/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0379 - acc: 0.7832 - mean_squared_error: 0.0379 - val_loss: 0.0376 - val_acc: 0.7856 - val_mean_squared_error: 0.0376\n",
      "Epoch 85/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0376 - acc: 0.7845 - mean_squared_error: 0.0376 - val_loss: 0.0378 - val_acc: 0.7823 - val_mean_squared_error: 0.0378\n",
      "Epoch 86/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0377 - acc: 0.7842 - mean_squared_error: 0.0377 - val_loss: 0.0377 - val_acc: 0.7833 - val_mean_squared_error: 0.0377\n",
      "Epoch 87/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0376 - acc: 0.7846 - mean_squared_error: 0.0376 - val_loss: 0.0376 - val_acc: 0.7858 - val_mean_squared_error: 0.0376\n",
      "Epoch 88/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0375 - acc: 0.7843 - mean_squared_error: 0.0375 - val_loss: 0.0377 - val_acc: 0.7816 - val_mean_squared_error: 0.0377\n",
      "Epoch 89/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0375 - acc: 0.7846 - mean_squared_error: 0.0375 - val_loss: 0.0373 - val_acc: 0.7864 - val_mean_squared_error: 0.0373\n",
      "Epoch 90/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0371 - acc: 0.7871 - mean_squared_error: 0.0371 - val_loss: 0.0372 - val_acc: 0.7867 - val_mean_squared_error: 0.0372\n",
      "Epoch 91/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0372 - acc: 0.7867 - mean_squared_error: 0.0372 - val_loss: 0.0373 - val_acc: 0.7825 - val_mean_squared_error: 0.0373\n",
      "Epoch 92/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0369 - acc: 0.7874 - mean_squared_error: 0.0369 - val_loss: 0.0370 - val_acc: 0.7857 - val_mean_squared_error: 0.0370\n",
      "Epoch 93/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0369 - acc: 0.7886 - mean_squared_error: 0.0369 - val_loss: 0.0368 - val_acc: 0.7892 - val_mean_squared_error: 0.0368\n",
      "Epoch 94/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0367 - acc: 0.7897 - mean_squared_error: 0.0367 - val_loss: 0.0367 - val_acc: 0.7872 - val_mean_squared_error: 0.0367\n",
      "Epoch 95/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0366 - acc: 0.7881 - mean_squared_error: 0.0366 - val_loss: 0.0365 - val_acc: 0.7888 - val_mean_squared_error: 0.0365\n",
      "Epoch 96/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0368 - acc: 0.7862 - mean_squared_error: 0.0368 - val_loss: 0.0365 - val_acc: 0.7868 - val_mean_squared_error: 0.0365\n",
      "Epoch 97/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0364 - acc: 0.7883 - mean_squared_error: 0.0364 - val_loss: 0.0364 - val_acc: 0.7870 - val_mean_squared_error: 0.0364\n",
      "Epoch 98/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0365 - acc: 0.7889 - mean_squared_error: 0.0365 - val_loss: 0.0363 - val_acc: 0.7874 - val_mean_squared_error: 0.0363\n",
      "Epoch 99/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0362 - acc: 0.7914 - mean_squared_error: 0.0362 - val_loss: 0.0364 - val_acc: 0.7871 - val_mean_squared_error: 0.0364\n",
      "Epoch 100/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0362 - acc: 0.7898 - mean_squared_error: 0.0362 - val_loss: 0.0362 - val_acc: 0.7905 - val_mean_squared_error: 0.0362\n",
      "Epoch 101/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0360 - acc: 0.7906 - mean_squared_error: 0.0360 - val_loss: 0.0363 - val_acc: 0.7883 - val_mean_squared_error: 0.0363\n",
      "Epoch 102/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0361 - acc: 0.7904 - mean_squared_error: 0.0361 - val_loss: 0.0359 - val_acc: 0.7890 - val_mean_squared_error: 0.0359\n",
      "Epoch 103/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0358 - acc: 0.7909 - mean_squared_error: 0.0358 - val_loss: 0.0361 - val_acc: 0.7876 - val_mean_squared_error: 0.0361\n",
      "Epoch 104/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0360 - acc: 0.7904 - mean_squared_error: 0.0360 - val_loss: 0.0358 - val_acc: 0.7905 - val_mean_squared_error: 0.0358\n",
      "Epoch 105/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0358 - acc: 0.7910 - mean_squared_error: 0.0358 - val_loss: 0.0359 - val_acc: 0.7858 - val_mean_squared_error: 0.0359\n",
      "Epoch 106/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0355 - acc: 0.7927 - mean_squared_error: 0.0355 - val_loss: 0.0356 - val_acc: 0.7897 - val_mean_squared_error: 0.0356\n",
      "Epoch 107/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0355 - acc: 0.7914 - mean_squared_error: 0.0355 - val_loss: 0.0355 - val_acc: 0.7927 - val_mean_squared_error: 0.0355\n",
      "Epoch 108/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0354 - acc: 0.7927 - mean_squared_error: 0.0354 - val_loss: 0.0354 - val_acc: 0.7917 - val_mean_squared_error: 0.0354\n",
      "Epoch 109/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0354 - acc: 0.7930 - mean_squared_error: 0.0354 - val_loss: 0.0355 - val_acc: 0.7886 - val_mean_squared_error: 0.0355\n",
      "Epoch 110/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0353 - acc: 0.7921 - mean_squared_error: 0.0353 - val_loss: 0.0352 - val_acc: 0.7921 - val_mean_squared_error: 0.0352\n",
      "Epoch 111/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0353 - acc: 0.7921 - mean_squared_error: 0.0353 - val_loss: 0.0353 - val_acc: 0.7887 - val_mean_squared_error: 0.0353\n",
      "Epoch 112/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0352 - acc: 0.7925 - mean_squared_error: 0.0352 - val_loss: 0.0353 - val_acc: 0.7895 - val_mean_squared_error: 0.0353\n",
      "Epoch 113/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0351 - acc: 0.7929 - mean_squared_error: 0.0351 - val_loss: 0.0352 - val_acc: 0.7926 - val_mean_squared_error: 0.0352\n",
      "Epoch 114/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0350 - acc: 0.7939 - mean_squared_error: 0.0350 - val_loss: 0.0351 - val_acc: 0.7940 - val_mean_squared_error: 0.0351\n",
      "Epoch 115/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0348 - acc: 0.7951 - mean_squared_error: 0.0348 - val_loss: 0.0354 - val_acc: 0.7911 - val_mean_squared_error: 0.0354\n",
      "Epoch 116/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0349 - acc: 0.7939 - mean_squared_error: 0.0349 - val_loss: 0.0351 - val_acc: 0.7901 - val_mean_squared_error: 0.0351\n",
      "Epoch 117/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0347 - acc: 0.7948 - mean_squared_error: 0.0347 - val_loss: 0.0352 - val_acc: 0.7923 - val_mean_squared_error: 0.0352\n",
      "Epoch 118/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0348 - acc: 0.7949 - mean_squared_error: 0.0348 - val_loss: 0.0352 - val_acc: 0.7901 - val_mean_squared_error: 0.0352\n",
      "Epoch 119/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0347 - acc: 0.7944 - mean_squared_error: 0.0347 - val_loss: 0.0349 - val_acc: 0.7916 - val_mean_squared_error: 0.0349\n",
      "Epoch 120/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0346 - acc: 0.7956 - mean_squared_error: 0.0346 - val_loss: 0.0349 - val_acc: 0.7923 - val_mean_squared_error: 0.0349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0346 - acc: 0.7954 - mean_squared_error: 0.0346 - val_loss: 0.0348 - val_acc: 0.7923 - val_mean_squared_error: 0.0348\n",
      "Epoch 122/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0345 - acc: 0.7955 - mean_squared_error: 0.0345 - val_loss: 0.0347 - val_acc: 0.7944 - val_mean_squared_error: 0.0347\n",
      "Epoch 123/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0343 - acc: 0.7967 - mean_squared_error: 0.0343 - val_loss: 0.0346 - val_acc: 0.7931 - val_mean_squared_error: 0.0346\n",
      "Epoch 124/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0345 - acc: 0.7957 - mean_squared_error: 0.0345 - val_loss: 0.0347 - val_acc: 0.7932 - val_mean_squared_error: 0.0347\n",
      "Epoch 125/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0343 - acc: 0.7964 - mean_squared_error: 0.0343 - val_loss: 0.0347 - val_acc: 0.7922 - val_mean_squared_error: 0.0347\n",
      "Epoch 126/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0343 - acc: 0.7965 - mean_squared_error: 0.0343 - val_loss: 0.0347 - val_acc: 0.7923 - val_mean_squared_error: 0.0347\n",
      "Epoch 127/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0343 - acc: 0.7957 - mean_squared_error: 0.0343 - val_loss: 0.0344 - val_acc: 0.7930 - val_mean_squared_error: 0.0344\n",
      "Epoch 128/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0342 - acc: 0.7970 - mean_squared_error: 0.0342 - val_loss: 0.0344 - val_acc: 0.7932 - val_mean_squared_error: 0.0344\n",
      "Epoch 129/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0341 - acc: 0.7972 - mean_squared_error: 0.0341 - val_loss: 0.0345 - val_acc: 0.7925 - val_mean_squared_error: 0.0345\n",
      "Epoch 130/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0340 - acc: 0.7969 - mean_squared_error: 0.0340 - val_loss: 0.0343 - val_acc: 0.7937 - val_mean_squared_error: 0.0343\n",
      "Epoch 131/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0341 - acc: 0.7974 - mean_squared_error: 0.0341 - val_loss: 0.0344 - val_acc: 0.7930 - val_mean_squared_error: 0.0344\n",
      "Epoch 132/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0340 - acc: 0.7975 - mean_squared_error: 0.0340 - val_loss: 0.0342 - val_acc: 0.7937 - val_mean_squared_error: 0.0342\n",
      "Epoch 133/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0339 - acc: 0.7982 - mean_squared_error: 0.0339 - val_loss: 0.0342 - val_acc: 0.7942 - val_mean_squared_error: 0.0342\n",
      "Epoch 134/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0341 - acc: 0.7976 - mean_squared_error: 0.0341 - val_loss: 0.0344 - val_acc: 0.7938 - val_mean_squared_error: 0.0344\n",
      "Epoch 135/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0339 - acc: 0.7991 - mean_squared_error: 0.0339 - val_loss: 0.0343 - val_acc: 0.7927 - val_mean_squared_error: 0.0343\n",
      "Epoch 136/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0338 - acc: 0.7983 - mean_squared_error: 0.0338 - val_loss: 0.0340 - val_acc: 0.7933 - val_mean_squared_error: 0.0340\n",
      "Epoch 137/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0338 - acc: 0.7985 - mean_squared_error: 0.0338 - val_loss: 0.0343 - val_acc: 0.7938 - val_mean_squared_error: 0.0343\n",
      "Epoch 138/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0339 - acc: 0.7981 - mean_squared_error: 0.0339 - val_loss: 0.0341 - val_acc: 0.7911 - val_mean_squared_error: 0.0341\n",
      "Epoch 139/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0337 - acc: 0.7986 - mean_squared_error: 0.0337 - val_loss: 0.0341 - val_acc: 0.7950 - val_mean_squared_error: 0.0341\n",
      "Epoch 140/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0336 - acc: 0.7995 - mean_squared_error: 0.0336 - val_loss: 0.0340 - val_acc: 0.7954 - val_mean_squared_error: 0.0340\n",
      "Epoch 141/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0335 - acc: 0.8001 - mean_squared_error: 0.0335 - val_loss: 0.0340 - val_acc: 0.7952 - val_mean_squared_error: 0.0340\n",
      "Epoch 142/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0336 - acc: 0.7992 - mean_squared_error: 0.0336 - val_loss: 0.0341 - val_acc: 0.7951 - val_mean_squared_error: 0.0341\n",
      "Epoch 143/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0335 - acc: 0.8008 - mean_squared_error: 0.0335 - val_loss: 0.0341 - val_acc: 0.7926 - val_mean_squared_error: 0.0341\n",
      "Epoch 144/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0335 - acc: 0.7997 - mean_squared_error: 0.0335 - val_loss: 0.0339 - val_acc: 0.7918 - val_mean_squared_error: 0.0339\n",
      "Epoch 145/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0335 - acc: 0.7989 - mean_squared_error: 0.0335 - val_loss: 0.0338 - val_acc: 0.7956 - val_mean_squared_error: 0.0338\n",
      "Epoch 146/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0333 - acc: 0.8011 - mean_squared_error: 0.0333 - val_loss: 0.0338 - val_acc: 0.7935 - val_mean_squared_error: 0.0338\n",
      "Epoch 147/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0336 - acc: 0.7994 - mean_squared_error: 0.0336 - val_loss: 0.0339 - val_acc: 0.7926 - val_mean_squared_error: 0.0339\n",
      "Epoch 148/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0335 - acc: 0.7986 - mean_squared_error: 0.0335 - val_loss: 0.0337 - val_acc: 0.7975 - val_mean_squared_error: 0.0337\n",
      "Epoch 149/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0333 - acc: 0.8007 - mean_squared_error: 0.0333 - val_loss: 0.0337 - val_acc: 0.7962 - val_mean_squared_error: 0.0337\n",
      "Epoch 150/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0333 - acc: 0.8003 - mean_squared_error: 0.0333 - val_loss: 0.0338 - val_acc: 0.7964 - val_mean_squared_error: 0.0338\n",
      "Epoch 151/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0332 - acc: 0.8009 - mean_squared_error: 0.0332 - val_loss: 0.0339 - val_acc: 0.7960 - val_mean_squared_error: 0.0339\n",
      "Epoch 152/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0335 - acc: 0.7996 - mean_squared_error: 0.0335 - val_loss: 0.0336 - val_acc: 0.7964 - val_mean_squared_error: 0.0336\n",
      "Epoch 153/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0333 - acc: 0.8009 - mean_squared_error: 0.0333 - val_loss: 0.0337 - val_acc: 0.7976 - val_mean_squared_error: 0.0337\n",
      "Epoch 154/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0333 - acc: 0.8005 - mean_squared_error: 0.0333 - val_loss: 0.0341 - val_acc: 0.7932 - val_mean_squared_error: 0.0341\n",
      "Epoch 155/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0333 - acc: 0.8007 - mean_squared_error: 0.0333 - val_loss: 0.0338 - val_acc: 0.7945 - val_mean_squared_error: 0.0338\n",
      "Epoch 156/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0332 - acc: 0.8010 - mean_squared_error: 0.0332 - val_loss: 0.0338 - val_acc: 0.7949 - val_mean_squared_error: 0.0338\n",
      "Epoch 157/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0333 - acc: 0.8003 - mean_squared_error: 0.0333 - val_loss: 0.0337 - val_acc: 0.7953 - val_mean_squared_error: 0.0337\n",
      "Epoch 158/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0332 - acc: 0.8018 - mean_squared_error: 0.0332 - val_loss: 0.0336 - val_acc: 0.7963 - val_mean_squared_error: 0.0336\n",
      "Epoch 159/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0331 - acc: 0.8016 - mean_squared_error: 0.0331 - val_loss: 0.0337 - val_acc: 0.7937 - val_mean_squared_error: 0.0337\n",
      "Epoch 160/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0331 - acc: 0.8013 - mean_squared_error: 0.0331 - val_loss: 0.0335 - val_acc: 0.7971 - val_mean_squared_error: 0.0335\n",
      "Epoch 161/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0330 - acc: 0.8027 - mean_squared_error: 0.0330 - val_loss: 0.0334 - val_acc: 0.7964 - val_mean_squared_error: 0.0334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0330 - acc: 0.8018 - mean_squared_error: 0.0330 - val_loss: 0.0337 - val_acc: 0.7944 - val_mean_squared_error: 0.0337\n",
      "Epoch 163/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0331 - acc: 0.8018 - mean_squared_error: 0.0331 - val_loss: 0.0338 - val_acc: 0.7941 - val_mean_squared_error: 0.0338\n",
      "Epoch 164/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0330 - acc: 0.8020 - mean_squared_error: 0.0330 - val_loss: 0.0335 - val_acc: 0.7979 - val_mean_squared_error: 0.0335\n",
      "Epoch 165/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0329 - acc: 0.8035 - mean_squared_error: 0.0329 - val_loss: 0.0334 - val_acc: 0.7944 - val_mean_squared_error: 0.0334\n",
      "Epoch 166/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0329 - acc: 0.8026 - mean_squared_error: 0.0329 - val_loss: 0.0333 - val_acc: 0.7983 - val_mean_squared_error: 0.0333\n",
      "Epoch 167/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0328 - acc: 0.8039 - mean_squared_error: 0.0328 - val_loss: 0.0333 - val_acc: 0.7958 - val_mean_squared_error: 0.0333\n",
      "Epoch 168/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0328 - acc: 0.8039 - mean_squared_error: 0.0328 - val_loss: 0.0335 - val_acc: 0.7970 - val_mean_squared_error: 0.0335\n",
      "Epoch 169/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0328 - acc: 0.8028 - mean_squared_error: 0.0328 - val_loss: 0.0336 - val_acc: 0.7983 - val_mean_squared_error: 0.0336\n",
      "Epoch 170/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0329 - acc: 0.8022 - mean_squared_error: 0.0329 - val_loss: 0.0333 - val_acc: 0.7982 - val_mean_squared_error: 0.0333\n",
      "Epoch 171/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0329 - acc: 0.8020 - mean_squared_error: 0.0329 - val_loss: 0.0333 - val_acc: 0.7969 - val_mean_squared_error: 0.0333\n",
      "Epoch 172/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0328 - acc: 0.8033 - mean_squared_error: 0.0328 - val_loss: 0.0334 - val_acc: 0.7978 - val_mean_squared_error: 0.0334\n",
      "Epoch 173/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0327 - acc: 0.8034 - mean_squared_error: 0.0327 - val_loss: 0.0334 - val_acc: 0.7964 - val_mean_squared_error: 0.0334\n",
      "Epoch 174/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0327 - acc: 0.8039 - mean_squared_error: 0.0327 - val_loss: 0.0333 - val_acc: 0.7978 - val_mean_squared_error: 0.0333\n",
      "Epoch 175/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0327 - acc: 0.8035 - mean_squared_error: 0.0327 - val_loss: 0.0332 - val_acc: 0.7956 - val_mean_squared_error: 0.0332\n",
      "Epoch 176/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0327 - acc: 0.8040 - mean_squared_error: 0.0327 - val_loss: 0.0333 - val_acc: 0.7982 - val_mean_squared_error: 0.0333\n",
      "Epoch 177/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0327 - acc: 0.8043 - mean_squared_error: 0.0327 - val_loss: 0.0333 - val_acc: 0.7975 - val_mean_squared_error: 0.0333\n",
      "Epoch 178/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0326 - acc: 0.8033 - mean_squared_error: 0.0326 - val_loss: 0.0331 - val_acc: 0.7977 - val_mean_squared_error: 0.0331\n",
      "Epoch 179/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0326 - acc: 0.8035 - mean_squared_error: 0.0326 - val_loss: 0.0333 - val_acc: 0.7960 - val_mean_squared_error: 0.0333\n",
      "Epoch 180/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0327 - acc: 0.8035 - mean_squared_error: 0.0327 - val_loss: 0.0335 - val_acc: 0.7966 - val_mean_squared_error: 0.0335\n",
      "Epoch 181/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0325 - acc: 0.8033 - mean_squared_error: 0.0325 - val_loss: 0.0333 - val_acc: 0.7969 - val_mean_squared_error: 0.0333\n",
      "Epoch 182/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0325 - acc: 0.8051 - mean_squared_error: 0.0325 - val_loss: 0.0333 - val_acc: 0.7986 - val_mean_squared_error: 0.0333\n",
      "Epoch 183/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0328 - acc: 0.8033 - mean_squared_error: 0.0328 - val_loss: 0.0337 - val_acc: 0.7950 - val_mean_squared_error: 0.0337\n",
      "Epoch 184/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0327 - acc: 0.8040 - mean_squared_error: 0.0327 - val_loss: 0.0335 - val_acc: 0.7969 - val_mean_squared_error: 0.0335\n",
      "Epoch 185/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0326 - acc: 0.8034 - mean_squared_error: 0.0326 - val_loss: 0.0331 - val_acc: 0.7979 - val_mean_squared_error: 0.0331\n",
      "Epoch 186/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0323 - acc: 0.8056 - mean_squared_error: 0.0323 - val_loss: 0.0329 - val_acc: 0.7994 - val_mean_squared_error: 0.0329\n",
      "Epoch 187/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0323 - acc: 0.8047 - mean_squared_error: 0.0323 - val_loss: 0.0334 - val_acc: 0.7977 - val_mean_squared_error: 0.0334\n",
      "Epoch 188/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0325 - acc: 0.8041 - mean_squared_error: 0.0325 - val_loss: 0.0331 - val_acc: 0.7971 - val_mean_squared_error: 0.0331\n",
      "Epoch 189/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0326 - acc: 0.8033 - mean_squared_error: 0.0326 - val_loss: 0.0332 - val_acc: 0.7970 - val_mean_squared_error: 0.0332\n",
      "Epoch 190/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0323 - acc: 0.8050 - mean_squared_error: 0.0323 - val_loss: 0.0331 - val_acc: 0.7978 - val_mean_squared_error: 0.0331\n",
      "Epoch 191/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0324 - acc: 0.8043 - mean_squared_error: 0.0324 - val_loss: 0.0331 - val_acc: 0.7962 - val_mean_squared_error: 0.0331\n",
      "Epoch 192/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0323 - acc: 0.8053 - mean_squared_error: 0.0323 - val_loss: 0.0331 - val_acc: 0.7987 - val_mean_squared_error: 0.0331\n",
      "Epoch 193/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0324 - acc: 0.8049 - mean_squared_error: 0.0324 - val_loss: 0.0333 - val_acc: 0.7962 - val_mean_squared_error: 0.0333\n",
      "Epoch 194/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0325 - acc: 0.8043 - mean_squared_error: 0.0325 - val_loss: 0.0331 - val_acc: 0.7966 - val_mean_squared_error: 0.0331\n",
      "Epoch 195/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0324 - acc: 0.8054 - mean_squared_error: 0.0324 - val_loss: 0.0332 - val_acc: 0.7984 - val_mean_squared_error: 0.0332\n",
      "Epoch 196/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0323 - acc: 0.8052 - mean_squared_error: 0.0323 - val_loss: 0.0332 - val_acc: 0.7954 - val_mean_squared_error: 0.0332\n",
      "Epoch 197/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0323 - acc: 0.8055 - mean_squared_error: 0.0323 - val_loss: 0.0330 - val_acc: 0.7973 - val_mean_squared_error: 0.0330\n",
      "Epoch 198/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0324 - acc: 0.8042 - mean_squared_error: 0.0324 - val_loss: 0.0334 - val_acc: 0.7948 - val_mean_squared_error: 0.0334\n",
      "Epoch 199/200\n",
      "60000/60000 [==============================] - 0s 1us/step - loss: 0.0323 - acc: 0.8048 - mean_squared_error: 0.0323 - val_loss: 0.0330 - val_acc: 0.7977 - val_mean_squared_error: 0.0330\n",
      "Epoch 200/200\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.0322 - acc: 0.8067 - mean_squared_error: 0.0322 - val_loss: 0.0330 - val_acc: 0.7982 - val_mean_squared_error: 0.0330\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating network for 784-dimensional input and 10-dimensional output, with 1 hidden layers\n"
     ]
    }
   ],
   "source": [
    "experiment = MNISTExperiment([10], 0.123, 0.321, epochs = 200, activation = 'sigmoid', reg_type = 0,\n",
    "                             reg_coeff = 0, do_print = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:17<03:16,  4.27s/it]"
     ]
    }
   ],
   "source": [
    "experiment.run(repetitions = 500000, inputs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = MNISTExperiment([10], 0.123, 0.321, epochs = 200, activation = 'sigmoid', reg_type = 0,\n",
    "                             reg_coeff = 0, do_print = True, train_dropout = [0.1, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.run(repetitions = 500000, inputs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = MNISTExperiment([10], 0.123, 0.321, epochs = 200, activation = 'sigmoid', reg_type = 'delta',\n",
    "                             reg_coeff = 0.01, do_print = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.run(repetitions = 500000, inputs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = MNISTExperiment([10], 0.123, 0.321, epochs = 200, activation = 'sigmoid', reg_type = 'l2',\n",
    "                             reg_coeff = 0.01, do_print = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.run(repetitions = 500000, inputs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Regularization with dropout, l2 and delta result in decrease of error\n",
    "2. Tightness is best for delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
